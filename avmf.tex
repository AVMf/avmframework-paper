\documentclass{llncs}

\usepackage{graphicx}
\usepackage{xspace}

\newcommand{\AVM}{Alternating Variable Method\xspace}
\newcommand{\longname}{AVM Framework\xspace}
\newcommand{\name}{AVM\hspace{-1pt}$f$\xspace}
\newcommand{\repourl}{\url{https://github.com/AVMf/avmf}\xspace}
\newcommand{\gitclone}{{\tt git clone https://github.com/AVMf/avmf.git}\xspace}
\newcommand{\inlineheading}[1]{\vspace{1ex} \noindent {\bf #1.}}
\newcommand{\codescalefactor}{0.7}

\newcommand{\snippet}[1]{
  \begin{center}
    \scalebox{\codescalefactor}{
      \begin{tabular}{|l|}
      \hline
      \input{snippets/#1}
      \hline
      \end{tabular}
    }
  \end{center}
}

\begin{document}

\title{\name ~--- An Open Source Framework and Implementation for use of the \\ \AVM}
\author{Suppressed for double-blind review}

\maketitle

\begin{abstract}
The \AVM (AVM) has been shown to be a particularly fast and effective local search technique in search-based software engineering.%, particularly test data generation.
%
Recent developments to the AVM have generalized the type of representation it can optimize, while others have provably improved its runtime for certain types of fitness landscape. However, there has been no publicly-available code implementation of these algorithms. We introduce \name, a  fully object-oriented framework, written in Java, that provides such an implementation. \name is ready for download and configuration for use in SBSE projects.

\end{abstract}

\section{Introduction}

\section{History of the AVM}

\section{Recent Improvements to the AVM}

\section{The \longname (\name)}
The \longname (\name) is an object-oriented framework and Java implementation of the AVM and its enhancements since the original version proposed by Korel. It is publicly available for download and use in SBSE projects at \repourl, a GitHub-hosted Git repository. In order to use \name, the repository must be cloned locally to a machine.

~\\
\name provides a framework of Java classes to enable the algorithms to be easily used in SBSE projects, which we now describe in detail below. Each aspect of the framework is practically demonstrated in the source code of the examples introduced at the end of this section.

\begin{sloppypar}
\inlineheading{Configuring an AVM search} The primary class is the {\tt AVM} class in the root ({\tt org.avmframework}) package. In order to construct an {\tt AVM} instance, the developer must supply an instance of one of the local search methods; {\tt IteratedPatternSearch}, {\tt GeometricSearch} or {\tt LatticeSearch}, which reside in the {\tt localsearch} package. The developer must also construct the {\tt AVM} instance with a {\tt TerminationPolicy}, an object that decides when the AVM should terminate, for example if an optimal solution is not found. Options include a maximum number of objective function evaluations, a maximum number of restarts, or a time threshold. Finally, constructing the {\tt AVM} instance requires instances of {\tt Initializer} that decide from where the algorithm starts the search and restarts the search, be it from the default values that can be specified for each variable or from a random position ({\tt DefaultInitializer} and {\tt RandomInitializer} respectively, which reside in the {\tt initializer} package). For random values, \name uses an instance of {\tt RandomGenerator} from the {\tt org.apache.commons} library. (All the examples provided with \name, described above, use the library's implementation of the Mersenne Twister algorithm.)
\end{sloppypar}

\begin{sloppypar}
In order to initiate a search process, the {\tt search} method of the {\tt AVM} instance must be invoked with an instance of a {\tt Vector} class and an {\tt ObjectiveFunction} respectively. The {\tt Vector} class describes the {\it representation} of the problem to the AVM, that is, the series of variables to be optimized; while the {\tt ObjectiveFunction} class describes how instances of those vectors should be rewarded. We now describe these aspects in further detail.
\end{sloppypar}

\begin{sloppypar}
\inlineheading{Representation} In order to configure the search representation, an instance of the {\tt Vector} class (in the root package) must be created, and variables added to it through the {\tt addVariable} method, which accepts an instance of a {\tt Variable}. {\tt Variable} is an abstract class, so an instance of one its concrete subclasses must be provided --- {\tt IntegerVariable}, {\tt FloatingPointVariable}, {\tt CharacterVariable} or {\tt StringVariable}. Each variable needs to be constructed with information such as its minimum or maximum value (maximum length for strings), precision in case of floating point variables, and a ``default'' initial value in the search space (e.g., the empty string or zero values). This values are used to set the variables to specific values if the {\tt DefaultInitializer} is used to start the search, as previously described.
\end{sloppypar}

\begin{sloppypar}
\inlineheading{Objective Function} In contrast to the rest of the framework, which require configuring instances of existing classes, an objective function is supplied to the search process by overriding the abstract {\tt ObjectiveFunction} (of the {\tt objective} package). This involves providing an implementation of the {\tt computeObjectiveValue} method, which takes a {\tt Vector} as a parameter and returns an instance of an {\tt ObjectiveValue}. Since the AVM only needs to know whether one class has a ``better'' objective value than another, exact numerical values are not needed, and so this class only provides ``betterThan'', ``worseThan'' and ``sameAs'' methods. This is useful for when a problem involves two objectives that must be optimized, but with some precedence (e.g., the classical ``approach level'' and ``branch distance'' components of the fitness function for structural test data generation \cite{}), avoiding the need for a normalization function to combine the values. % Arcuri, Poulding GECCO reference.
Nevertheless, the {\tt objective} package also supplies a concrete {\tt NumericalObjectiveValue} class for returning higher-is-better or lower-is-better numerical objective values.
\end{sloppypar}

\begin{sloppypar}
\inlineheading{Reporting} The {\tt search} method of the {\tt AVM} class returns an instance of the {\tt Monitor} class, which can be used to find out interesting statistics regarding the search. These include the best vector found by the search, its objective value, the number of objective function evaluations that took place, the number of restarts that took place, and the amount of time that the search took (in milliseconds). The {\tt Monitor} class can also report the number of {\it unique} objective function evaluations. The objective function can make optional usage of a cache that maps previously ``seen'' vectors to objective values (a feature that is turned on by default). Using this cache helps make the search process more efficient by not repeating potentially expensive objective function evaluations for vectors that have already been considered during the search.
\end{sloppypar}

\inlineheading{Examples} \name comes with three small examples demonstrating its use. (Instructions on how to compile and run these examples are available in the project's {\tt README.md} file.) The first, {\tt Quadratic} demonstrates the use of the AVM to solve a quadratic equation by finding one of its roots. The {\tt AllZeroes} example demonstrates the optimization of an array of integers to zero values, from arbitrary random values. Finally, {\tt String} optimizes a string value from an initially random string to the value ``{\tt \AVM}''. The examples can be configured with a command line parameter to use IPS, Geometric or Lattice search as the local search method.

Each example makes use of its own problem-specific fitness function that can be seen as part of its code definition. The example below is taken from the {\tt Quadratic} class:

% TODO: explain, what are A, B, C etc.

\snippet{objective-fn}

The following is the output of the search process, showing how the AVM search correctly found one of the roots, $-1.5$:

\snippet{search-output}

\section{Potential Further Uses of the AVM in Search-Based Software Engineering}

\inlineheading{Automatically Generating Readable Test Data}

\inlineheading{Automatically Finding Optimal Software Configurations}

\inlineheading{Automated Bug-Fixing}

\section{Conclusions}

%% Commented out for double blind review
%\inlineheading{Acknowledgment}
%We thank Joseph Kempka for an initial implementation of Geometric and Lattice search that we used to test our own version against.

\end{document}
